# Применение AI в разработке ПО — Полный текст доклада (для зачитывания)

> Формат: **слайд → полный текст докладчика**. Скрипт написан так, чтобы его можно было читать дословно.
> Общая длительность: ~35 минут контента + 15 минут Q&A. Рекомендуется держать темп 130–150 слов/мин и делать короткие паузы между блоками.

---

## Раздел 1. Вступление (≈5 минут, 5 слайдов)

### Слайд 1. «AI в разработке ПО: зачем это нам сейчас?»
**Тезисы:**
- Массовое внедрение: **Copilot/ChatGPT/Codeium/Cursor**
- Эволюция: **автодополнение → ассистенты → агенты**
- Категории: **IDE**, **чаты**, **спец‑тулы**, **локальные**
- Цель доклада: **прагматика**, не хайп

**Текст докладчика**  
Коллеги, всем привет! Сегодня мы поговорим о том, как использовать AI в разработке так, чтобы выиграть в скорости, но не проиграть в качестве. 

Почему эта тема важна именно сейчас? За последние один‑два года инструменты вроде GitHub Copilot, ChatGPT, Codeium, Cursor и локальные LLM перестали быть игрушками и превратились в нормальные рабочие инструменты. Мы наблюдаем эволюцию от простого автодополнения к осмысленным подсказкам, генерации тестов, рефакторингу и даже к «агентам», которые читают кодовую базу и предлагают изменения. Есть облачные помощники, есть локальные модели для приватных проектов. Порог входа низкий: поставить плагин — и у вас уже второй мозг под рукой.

При этом вокруг много мифов: от «AI сделает всё сам» до «это всё не работает». Наша цель сегодня — трезво разобраться, где AI уже приносит пользу, где ограничения, и как встроить его в процесс так, чтобы не ломать инженерные практики и стандарты команды.

---

### Слайд 2. «LLM: как работают + термины»
**Тезисы:**
- **LLM**: статистическое предсказание P(токен|контекст)
- **Промпт**: роль + задача + ограничения + формат ответа
- **RAG**: поиск релевантного контекста + генерация
- **Вайб‑кодинг**: быстрые черновики с AI при неполной спецификации
- **DoD**: критерии готовности задачи

**Текст докладчика**  
Прежде чем говорить о практиках, разберёмся в терминах и механике работы.

**LLM (большие языковые модели):** Статистическое предсказание следующего токена на основе контекста — P(токен|контекст). Модели обучались на коде, документации, Stack Overflow. Они выучили паттерны, но это не понимание — только продолжение последовательностей. Контекстное окно ограничено (4K-128K токенов), поэтому важен релевантный контекст.

**Промпт:** Описание роли модели, задачи, инструментов и ограничений. Формула: роль → контекст → задача → ограничения → формат ответа.

**RAG (Retrieval-Augmented Generation):** Поиск релевантного контекста из репозитория, документации, ADR плюс генерация на его основе. Особенно полезно для локальных моделей.

**Вайб‑кодинг:** Быстрые черновики с AI при неполной спецификации. Полезно для прототипов и рутины, но не для безопасности и критичных систем.

**DoD (Definition of Done):** Критерии готовности задачи, которые фиксируем заранее для качества результата.

---

### Слайд 3. «Что такое AI‑assisted development»
**Тезисы:**
- **Партнёр**, а не замена
- Человек отвечает за **архитектуру/безопасность**
- Лучшее применение: **boilerplate, черновики**
- **Тесты/ревью**: обязательные рамки

**Текст докладчика**  
AI‑assisted development — это не магическая замена программистов. Это следующий уровень инструментов — как когда‑то Git, CI/CD и статический анализ. Удобная метафора: опытный стажёр. Он быстро делает черновики, подсказывает варианты и напоминает про подводные камни. Но ответственность за архитектуру, безопасность, компромиссы и качество остаётся на нас. Ошибки у моделей будут — и наша задача выстроить процесс, где эти ошибки отлавливаются тестами, ревью и мониторингом.

---

### Слайд 4. «AI как консультант до кода»
**Тезисы:**
- **Вопросы стейкхолдерам**: что упустили в требованиях
- **Выбор методов**: сравнение подходов + компромиссы
- **Поиск узких мест**: производительность, безопасность, масштабируемость
- **Декомпозиция**: разбивка на подзадачи с DoD

**Текст докладчика**  
Самая большая польза от AI часто появляется ещё до первой строки кода. AI работает как опытный консультант, который помогает превратить описание эпика или требования заказчика в конкретный набор технологий, этапов разработки и задач.

**Декомпозиция задач:** Просим модель разбить "сделать авторизацию" на подзадачи: выбор протокола (OAuth2/OIDC/SAML), настройка провайдера, middleware для проверки токенов, роли и права, логирование, метрики безопасности. Каждая подзадача получает чёткие критерии приёмки.

**Выбор методов реализации:** AI помогает сравнить подходы. Например, для кэширования: Redis vs Memcached vs in-memory. Модель анализирует наши требования (персистентность, кластеризация, сложные структуры) и предлагает взвешенное решение с плюсами и минусами каждого варианта.

**Поиск узких мест:** AI заранее выявляет потенциальные проблемы. Для API с высокой нагрузкой — предлагает рассмотреть rate limiting, connection pooling, асинхронную обработку, мониторинг метрик. Для работы с файлами — предупреждает про memory leaks при больших файлах, предлагает streaming.

**Вопросы стейкхолдерам:** AI формулирует вопросы, которые мы могли упустить. "Какой максимальный размер файла?", "Нужна ли поддержка мобильных устройств?", "Какие требования к доступности?", "Есть ли ограничения по лицензиям?". Это превращает туман в план.

---

## Раздел 2. Вайб‑кодинг: мифы и реальность (≈6 минут, 4 слайда)

### Слайд 1. «Что такое вайб‑кодинг»
**Тезисы:**
- Быстрые **черновики с AI**
- Где можно: **прототипы/рутина**
- Где нельзя: **безопасность/деньги/SLA/PII**
- Цель: **скорость в рамках**

**Текст докладчика**  
Вайб‑кодинг — это быстрый стиль, когда мы просим AI сгенерировать черновое решение при неполной спецификации. Это очень полезно для прототипов, документации и повторяющихся задач. Но есть зоны, где так работать нельзя: безопасность, деньги, PII, жёсткие SLA, миграции данных. В этих зонах — сначала проектирование и аудит, затем реализация.

---

### Слайд 2. «Мифы о вайб‑кодинге — все сразу»
**Тезисы:**
- **Миф 1**: AI сделает всё → реальность: **30–70% рутины**
- **Миф 2**: потом поправим → долг **растёт экспоненциально**
- **Миф 3**: AI лучше знает → **P(token|контекст)** сужает распределение
- **Миф 4**: один промпт → лучше **план → код → самопроверка**
- **Миф 5**: код готов к проду → частые **XSS/SSRF/JWT** уязвимости

**Текст докладчика**  
Пять основных мифов о вайб‑кодинге и реальность:

**Миф 1: AI сделает всё.** Реальность: AI закрывает 30–70% рутины — болванки, DTO, мапперы, валидацию, простые CRUD. Но архитектурные решения остаются на нас.

**Миф 2: потом поправим.** Сырые подсказки прячут магические числа, отсутствие таймаутов, пустые catch без логов. Технический долг растёт быстрее экономии времени.

**Миф 3: AI лучше знает.** LLM предсказывают P(токен|контекст). Чем лучше контекст, тем меньше «галлюцинаций». Даём модели опоры: контракты, схемы, примеры кода.

**Миф 4: один промпт — готово.** Лучше три итерации: план → реализация → самопроверка. Промпт уровня задачи, не отдельных строк.

**Миф 5: код готов к проду.** AI предлагает популярные, но небезопасные паттерны: JWT без проверки `iss`/`aud`, общие секреты, отсутствие валидации.

**Что делаем на практике:**
- **Мини‑спека с DoD** перед кодом
- **Примеры из репо** (20–40 строк стиля)
- **Security‑чеклист** на каждое ревью
- **Маленькие PR** для быстрого отката

---

### Слайд 3. «Антипаттерны вайб‑кодинга»
**Тезисы:**
- **Cargo‑cult**: копирование ответов
- **Пустые catch**, магические таймауты
- **Глобальное состояние**, «тесты потом»
- Нет **логов/метрик**
- Нет **фиксации в ARD**
- Нет **документации**

**Текст докладчика**  
Красные флажки легко узнаются: cargo‑cult — «делаю как в ответе», магические таймауты и ретраи, глобальная статика, пустые catch без логов, обещание «докинем тесты потом». Лечится это чек‑листами ревью, политикой, что тесты и observability — это часть задачи, и маленькими PR, чтобы упростить ревью и откат.

---

### Слайд 4. «Шаблоны запросов к моделям»
**Тезисы:**
- **4 базовых шаблона**: декомпозиция, тесты, код, аудит
- **Стандартизация**: вся команда говорит одним языком
- **CONTRIBUTING.md**: шаблоны доступны всем
- **Качество**: предсказуемые результаты

**Текст докладчика**  
Ключевая практика — стандартизация промптов. Используем четыре базовых шаблона для разных этапов работы.

**Шаблон 1 — Декомпозиция:** «Разбей задачу [описание] на подзадачи с DoD и рисками. Укажи зависимости, оценки времени и критерии приёмки. Формат: таблица с колонками Подзадача, DoD, Риски, Время.»

**Шаблон 2 — Тест-скелеты:** «Сгенерируй тест-скелеты для [модуль/функция]. Покрой happy path, edge cases и ошибки. Укажи, что мокать. Формат: код тестов + список моков.»

**Шаблон 3 — Код под тесты:** «Сделай patch для [функция] под эти тесты. Следуй стилю проекта, добавь логирование и обработку ошибок. Формат: diff с изменениями.»

**Шаблон 4 — Самоаудит:** «Проверь этот код по чек-листу: безопасность, производительность, читаемость, покрытие тестами, обработка ошибок. Формат: таблица с результатами проверки.»

Выносим эти шаблоны в CONTRIBUTING.md, чтобы вся команда говорила с ассистентами одним языком. Это даёт предсказуемые результаты и экономит время на объяснения.

---

## Раздел 3. Инструменты и лучшие практики (≈12 минут, 9 слайдов)

### Слайд 1. «Цель раздела»
**Тезисы:**
- Карта **инструментов**
- Процесс: **контекст → промпт → IDE/CI**
- **Ревью/комплаенс** как рамки
- **Метрики** успеха

**Текст докладчика**  
В этом блоке быстро разложим экосистему инструментов на четыре класса и договоримся о процессе: как давать контекст, как формулировать запросы, куда встраивать AI в IDE и CI, как ревьюить и какие юридические вопросы держать под контролем.

---

### Слайд 2. «Карта инструментов»
**Тезисы:**
- **IDE**: Copilot/Cursor/Codeium/Tabnine
- **Чаты**: ChatGPT o1/Claude/DeepSeek
- **Спец‑тулы**: CodiumAI/Sourcery/Cody
- **Локальные**: Ollama/Llama.cpp

**Текст докладчика**  
Разложим экосистему на четыре класса инструментов.

**IDE‑ассистенты:** GitHub Copilot — самый популярный, интегрируется в VS Code, IntelliJ, Vim. Cursor — IDE с встроенным AI, отличный для быстрого прототипирования. Codeium — бесплатный аналог Copilot с хорошим качеством подсказок. Tabnine — один из первых, поддерживает локальные модели. Все они работают инлайн, понимают контекст файла и предлагают автодополнение.

**Чат‑агенты:** ChatGPT 5 — новейшая модель OpenAI с улучшенным рассуждением, отлично подходит для архитектурных решений. Claude 4 Sonnet — лучший для анализа кода и рефакторинга, отличное понимание контекста. DeepSeek — мощная модель с большим контекстным окном, хороша для работы с большими кодовыми базами.

**Специализированные инструменты:** CodiumAI — генерирует тесты, анализирует покрытие, предлагает edge cases. Sourcery — автоматический рефакторинг, упрощение кода, соблюдение принципов SOLID. Cody/Sourcegraph — поиск по кодовой базе, понимание зависимостей, отличны для больших проектов и монорепозиториев.

**Локальные модели:** Ollama — простой запуск локальных моделей, поддержка Llama, CodeLlama, Mistral. Llama.cpp — высокопроизводительный инференс, оптимизирован для CPU. Полезны для приватных проектов и работы без интернета.

Каждому классу есть своё место в процессе: IDE — для ежедневного кодинга, чаты — для планирования и анализа, спец‑тулы — для конкретных задач, локальные — для приватности.

---

### Слайд 3. «IDE‑ассистенты»
**Тезисы:**
- Сильны: **инлайн‑код, boilerplate, тест‑скелеты**
- Кейсы: **DTO/CRUD/валидаторы/README**
- Приём: **выдели фрагмент + ожидаемый diff**
- Не для **архитектуры**

**Текст докладчика**  
Сильная сторона IDE‑инструментов — инлайн‑подсказки. Они отлично справляются с boilerplate, DTO, CRUD, валидаторами и README. Тактика: выделить фрагмент кода и чётко сформулировать результат — например, «добавь обработку ошибок и логирование, верни patch». Для фронта — шаблоны форм и пайпы, для бэка — контроллеры, DTO и обработчики ошибок.

---

### Слайд 4. «LLM‑агенты (чат) — архитектурный консультант»
**Тезисы:**
- Сильны: **декомпозиция/ADR/миграции**
- **Большой контекст** (OpenAPI/схемы/ADR)
- **Сравнение подходов**: микросервисы vs монолит
- Форматы: **чек‑лист/таблица/patch**

**Текст докладчика**  
Чат‑агенты работают как архитектурный консультант. Они хороши для декомпозиции, сравнения подходов, черновиков ADR, планов миграций, списков рисков. 

**Пример архитектурного решения:** Просим сравнить микросервисы vs монолит для нашего проекта. AI анализирует контекст: команда 8 человек, 3 домена, частота изменений, требования к масштабированию. Выдаёт таблицу: плюсы/минусы, сложность внедрения, риски, рекомендации с обоснованием.

**Большой контекст:** Даём OpenAPI схемы, существующие ADR, примеры кода из репозитория. AI понимает наши паттерны и предлагает решения в том же стиле. Ключ: явно задать ограничения и формат ответа, иначе получите красивый, но расплывчатый текст.

---

### Слайд 5. «Специализированные инструменты»
**Тезисы:**
- **CodiumAI**: тесты/покрытие
- **Sourcery**: рефакторинг/упрощение
- **Cody/Sourcegraph**: поиск/контекст
- Использовать в **песочнице PR**

**Текст докладчика**  
Специализированные инструменты бьют прицельно. CodiumAI подсказывает тесты, помогает закрыть пробелы покрытия. Sourcery помогает упростить код и провести рефакторинг. Cody/Sourcegraph обеспечивает поиск и контекст в больших репозиториях и монорепах. Лучшая практика — запускать их в рамках PR и использовать как источник подсказок, а не как «автослияние».

---

### Слайд 6. «Локальные модели: Ollama, Llama.cpp»
**Тезисы:**
- Когда: **приватность/офлайн**
- Плюсы/минусы: **контроль vs ресурсы**
- Паттерн: **RAG по репо/ADR**
- Требуются **индексы/политики доступа**

**Текст докладчика**  
Локальные модели полезны там, где нельзя выносить код или данные в облако. Их плюсы — контроль и кастомизация, минусы — требования к ресурсам и необходимость хорошей упаковки контекста. Рабочий паттерн — Retrieval‑Augmented Generation: индексируем документацию, ADR и код, и подсовываем модели релевантные куски на каждый запрос.

---

### Слайд 7. «AI как пара глаз»
**Тезисы:**
- **Черновики/boilerplate**, самопроверка
- Цикл: **план → код → self‑check**
- Ловим **edge‑кейсы** заранее
- **Меньше времени** на ревью

**Текст докладчика**  
Относимся к AI как к внимательному стажёру. Пускай сначала предлагает план, затем пишет код, затем проверяет себя по чек‑листу. Короткие итерации с обратной связью резко улучшают качество кода и снижают объём мусора в PR.

---

### Слайд 8. «Правильные промпты»
**Тезисы:**
- **Примеры** из репо (20–40 строк)
- **Ограничения**: версии/таймауты/формат
- **Явный DoD** покрытие тестами
- Антипаттерн: «**сделай красиво**»

**Текст докладчика**  
Секрет в контексте: примеры из репозитория — 20–40 строк, где видно стиль, логи и обработку ошибок. Плюс ограничения: версии, таймауты, формат ошибок, i18n, требования безопасности. И обязательно указываем формат ответа: patch, таблица, файл. Плохой промпт — «сделай красиво». Хороший — конкретный и проверяемый.


---

### Слайд 9. «Ревью человеком — обязательно»
**Тезисы:**
- Чек‑лист: **корректность/безопасность/производительность/поддерживаемость**
- **Красные зоны**: крипто/платежи/PII
- **Трейсабильность** решений
- **Block merge** без тестов

**Текст докладчика**  
Каждый AI‑патч проходит обычную полосу препятствий: корректность, безопасность, производительность, поддерживаемость и совместимость. Мы осознанно ищем антипаттерны — магические числа, пустые catch, скрытые глобальные состояния и неконтролируемые ретраи. Отношение к коду написанному AI должно быть точно такое же, как к коду написанному Стажером - пусть это и быстро и выглядит красиво, но модель обучалась на открытом коде, а не на идеальных примерах

---

## Раздел 4. Практические примеры (≈12 минут, 4 слайда)

### Слайд 1. «План примеров»
**Тезисы:**
- **Тесты**, **REST API**, **рефакторинг**
- **Документация/миграции**, **внутренний кейс**
- **Планирование проекта** с AI-консультантом
- Метрики: **покрытие/p95/дефекты**

**Текст докладчика**  
Дальше — пять коротких сценариев: генерация тестов для существующего модуля, быстрый прототип REST API под согласованный контракт, рефакторинг наследия, документация и миграции, и один мини‑кейс из нашей кодовой базы. 

**Плюс новый сценарий:** планирование проекта с AI-консультантом. Покажем, как AI помогает разложить большую фичу на спринты, выявить зависимости между задачами, предложить порядок реализации и спрогнозировать риски. Каждый сценарий показывает конкретную пользу и набор рамок, которые сохраняют качество.


### Слайд 2. «Пример 2 — прототип REST API под контракт»
**Тезисы:**
- Контекст: **OpenAPI + DTO** (TypeScript/Angular)
- Запрос: **контроллер/валидация/ошибки**
- DoD: **статусы/безопасность/метрики**
- Риски: **таймауты/нагрузка/совместимость**

**Текст докладчика**  
Наш стек: TypeScript на фронте, Node.js на бэке, Angular для UI. На входе — OpenAPI и DTO фронта. Просим модель сгенерировать контроллер с валидацией через Joi, обработку ошибок по нашему RFC 7807 формату, авторизацию через JWT middleware и наблюдаемость через Prometheus метрики. Definition of Done: соблюдён контракт, валидация корректная, ошибки в формате `{type, title, status, detail}`, безопасность настроена, есть логи и метрики с префиксом `api_`. Риски: таймауты (лимит 30с), нагрузка (1000 RPS), совместимость версий API. Мы их проговариваем и намечаем спайки.

---


### Слайд 3. «Пример 4 — документация и миграции»
**Тезисы:**
- Черновик: **README/ADR/гайд**
- DoD: **шаги/команды/rollback/риски**
- Проверка: **чистая машина**
- Ответственность: **владелец**

**Текст докладчика**  
AI отлично пишет черновики README, ADR и миграционных инструкций. Наша задача — проверяем воспроизводимость: инструкции должны работать на чистой машине. Definition of Done: пошаговые команды, параметры, варианты отката и список рисков. Это экономит время на онбординг и снижает «устную историю» в команде.

---

### Слайд 4. «Пример 5 — планирование проекта с AI»
**Тезисы:**
- Задача: **большая фича** (например, система уведомлений)
- **Декомпозиция**: спринты + зависимости
- **Риски**: интеграции, производительность, UX
- **Порядок**: MVP → расширения → оптимизация

**Текст докладчика**  
Пример: планируем систему уведомлений (email, push, SMS). AI разложил на спринты: MVP с email (2 спринта), интеграция с провайдерами (1 спринт), push-уведомления (2 спринта), SMS и веб-хуки (1 спринт), админка и аналитика (1 спринт). 

**Зависимости:** AI выявил критический путь: сначала инфраструктура очередей, затем провайдеры, потом UI. Предложил параллельно разрабатывать фронт и бэк.

**Риски:** Модель заранее предупредила про rate limits провайдеров, необходимость fallback-каналов, требования GDPR для email, производительность при массовых рассылках.

**Результат:** Чёткий план на 7 спринтов с пониманием рисков и зависимостей.

---

## Раздел 5. Будущее и куда всё идёт (≈8 минут, 5 слайдов)

### Слайд 1. «Тренды»
**Тезисы:**
- Стандарт: **человек+модель**
- Роль: **архитектура/ревью/контроль**
- Модели: всё более **инструментальные**
- Влияние: **измеримо метриками**

**Текст докладчика**  
Норма будущего — человек и модель, работающие вместе. Роль инженера смещается к постановке задач, выбору компромиссов, контролю качества и объяснению решений. Модели становятся инструментальными: лучше работают с контекстом, файлами и артефактами процесса.

---

### Слайд 2. «Агентный подход»
**Тезисы:**
- **PR/issue**: автоген и поддержка
- **Guardrails**: тесты/политики
- **Наблюдаемость** за агентами
- **Human‑in‑the‑loop**

**Текст докладчика**  
Агенты исполняют план: собирают контекст, предлагают изменения, открывают PR. Но они проходят через те же ворота — тесты, политики, ревью. Мы измеряем результат и держим наблюдаемость за агентами, чтобы понимать, где они ошибаются и как улучшать процесс.

---

### Слайд 3. «AI в DevOps»
**Тезисы:**
- CI: **аннотации/автодоки**
- Тесты: **поиск флейков**
- Ops: **runbooks/postmortems**
- Алерты: **триаж‑подсказки**

**Текст докладчика**  
В CI ассистенты помогают с аннотациями к ошибкам, автодоками для PR, подсказками по нестабильным тестам. В эксплуатации — помогают с алертами, готовят черновики runbooks и постмортемов. Это снижает время реакции и повышает прозрачность.

---

### Слайд 4. «Персонализация моделей»
**Тезисы:**
- **RAG** по репо/ADR/тикетам
- Тюнинг под **стиль команды**
- **Границы знаний** и доступов
- **Рост метрик**: скорость/дефекты

**Текст докладчика**  
Персонализация — это настройка AI под специфику вашего проекта и команды.

**RAG по репозиторию:** Индексируем код, ADR, тикеты и документацию. Например, для Qwen Code настраиваем векторную базу с эмбеддингами кода. При запросе модель получает релевантные фрагменты из вашего репо — паттерны архитектуры, стиль кода, принятые решения. Это даёт контекстно-релевантные ответы вместо общих рекомендаций.

**Тюнинг под стиль команды:** Анализируем существующий код команды — именование переменных, структуру функций, обработку ошибок. Настраиваем промпты так, чтобы AI генерировал код в том же стиле. Например, если команда использует `Result<T, Error>` вместо исключений, AI будет предлагать такой же подход.

**Границы знаний:** Определяем, что модель знает о проекте (архитектура, домены, ограничения) и что не знает (секреты, приватные данные). Настраиваем контекстные окна и фильтры доступа.

**Метрики эффективности:** Скорость разработки (строки кода/час), дефекты в продакшене (баги/1000 строк), производительность (p95 время ответа), время восстановления (MTTR). Когда эти цифры улучшаются на 20-30%, скепсис уходит сам собой.

---

### Слайд 5. «Риски и governance»
**Тезисы:**
- **Lock‑in**, приватность, **drift**
- **Политики/аудит/обучение**
- Дорожная карта: **пилот → масштаб**
- **Прозрачность** решений

**Текст докладчика**  
Управляем рисками: lock‑in, приватность, дрейф поведения моделей. Вводим политики использования, аудит и обучающие гайды. Делаем дорожную карту внедрения: пилот, метрики, масштабирование. Это превращает «хайп» в устойчивую практику.

---

## Раздел 6. Заключение + Q&A (≈3 минуты + 15 минут Q&A, 2 слайда)

### Слайд 1. «Ключевые тезисы»
**Тезисы:**
- AI = **ускоритель**, не замена инженерии
- Основа: **контекст/DoD/тесты/ревью**
- Интеграция в **IDE/CI/CD**
- Соблюдаем **секреты/лицензии**

**Текст докладчика**  
Итак: AI — это инструмент‑ускоритель, а не замена инженерии. Качество появляется через контекст, DoD, тесты и ревью. Инструменты нужно встраивать в IDE и CI/CD и соблюдать комплаенс по секретам и лицензиям. В таком наборе рамок скорость не разрушает качество, а помогает его достичь быстрее.

---

### Слайд 2. «План на 30 дней + вопросы»
**Тезисы:**
- **Пилот**: 1 команда, 2–3 кейса
- **Метрики**: скорость/дефекты/p95/coverage
- **Шаблоны промптов**, политика секретов
- **Q&A**

**Текст докладчика**  
Предлагаю простой стартовый план на месяц: одна пилотная команда и два‑три типовых кейса — генерация тестов, прототип API под контракт и рефакторинг. Фиксируем метрики: скорость, дефекты, p95 и покрытие. Выкатываем политику секретов и лицензий, добавляем в репозиторий шаблоны промптов. По результатам пилота — масштабируем. На этом у меня всё, с радостью отвечу на ваши вопросы.
